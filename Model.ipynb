{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dLpRWmTdh1sV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Text\n",
        "text = open('iphone_train.txt', 'r').read()\n",
        "text = text.split('\\n')"
      ],
      "metadata": {
        "id": "kERqRBR0iGlT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove non letter characters\n",
        "new_text = []\n",
        "\n",
        "#Looks through each charcter and replaces non letter characters with nothing\n",
        "for new_line in text:\n",
        "  for char in new_line:\n",
        "    if char in '!@#$%^&*()_+=,._;[]{}\\|?\"\"''':\n",
        "      new_line = new_line.replace(char, '')\n",
        "  new_text.append(new_line)"
      ],
      "metadata": {
        "id": "NmUD-Pl7NCXR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(new_text)\n",
        "\n",
        "#Create Inputs\n",
        "input = []\n",
        "\n",
        "#each word in tect tokenize and add to imput list\n",
        "for word in new_text:\n",
        "  tokens = tokenizer.texts_to_sequences([word])[0]\n",
        "  for i in range(1, len(tokens)):\n",
        "        n_gram_sequence = tokens[:i+1]\n",
        "        input.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "7wR2IC6xNvvS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Setup\n",
        "import numpy as np\n",
        "\n",
        "#Pad\n",
        "max_length = max([len(x) for x in input])\n",
        "input = tf.keras.preprocessing.sequence.pad_sequences(input, maxlen=max_length, padding='pre')\n",
        "\n",
        "length = len(tokenizer.word_index) + 1\n",
        "\n",
        "#x and y inputs\n",
        "x, y = input[:, :-1], input[:, -1]\n",
        "\n",
        "#vectorize y\n",
        "y = np.array(tf.keras.utils.to_categorical(y, num_classes=length))"
      ],
      "metadata": {
        "id": "koVcngYeRGj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(length, 100, input_length=max_length-1))\n",
        "model.add(LSTM(300))\n",
        "model.add(Dense(length, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "kgaj-5wHU07O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=50, verbose=1)"
      ],
      "metadata": {
        "id": "6CbFoZbmU_32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('Model.h5')"
      ],
      "metadata": {
        "id": "qYikp2e6VG4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accur = model.evaluate(x,y, verbose=0)\n",
        "print('The models accuracy is : '+ str(100*accur[1])+'%')"
      ],
      "metadata": {
        "id": "xZtGi3TTVLX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Model_1.h5', save_format='h5')"
      ],
      "metadata": {
        "id": "oWrlpK8BVRwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.array(list(tokenizer.word_index.keys()))"
      ],
      "metadata": {
        "id": "2uwzpnElVT1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_predict = 'Hello'\n",
        "next_words = 5\n",
        "\n",
        "for words in range(next_words):\n",
        "  token_predict = tokenizer.texts_to_sequences([text_to_predict])\n",
        "  pad_text = tf.keras.preprocessing.sequence.pad_sequences(token_predict, maxlen=16)\n",
        "\n",
        "  prediction_prob = model.predict(pad_text)\n",
        "  prediction_word = tokenizer.index_word[np.argmax(prediction_prob)]\n",
        "\n",
        "  text_to_predict += \" \" + prediction_word\n",
        "\n",
        "print(text_to_predict)"
      ],
      "metadata": {
        "id": "WaM9KGgyVW0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}